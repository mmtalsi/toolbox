import glob
import re
from bs4 import BeautifulSoup
import datetime
import os

def lire_rapport_txt(path):
    if os.path.exists(path):
        with open(path, 'r', encoding='utf-8') as f:
            return f.read()
    return "Aucun contenu disponible."

def extraire_domaine_depuis_rapport(texte):
    m = re.search(r"Domain Analysis Report for ([\w\.-]+)", texte)
    return m.group(1) if m else "inconnu.local"

def detecter_outils_executes(texte):
    outils = []
    def sv(n, excl): return n in texte and excl not in texte
    if sv("SCAN NIKTO", "Aucun r√©sultat"):     outils.append("Nikto")
    if sv("DETECTE LOGIN PAGE", "Aucun r√©sultat"): outils.append("DIRB")
    if sv("REDIRECTIONS D√âTECT√âES", "Aucune redirection"): outils.append("DIRB")
    if "SCAN Reconnaissance Domaine" in texte:
        for o in ("Subfinder","WebTech","WHOIS"):
            if o in texte: outils.append(o)
    if sv("SCAN XSS", "Aucun r√©sultat"):       outils.append("ParamSpider / XSS")
    if sv("SCAN INJECTION SQL", "Aucun r√©sultat"): outils.append("SQLMap")
    if sv("INFORMATIONS SERVEUR ET EN-T√äTES", "Aucune information"): outils.append("Header Check")
    if sv("PORTS OUVERTS ET SERVICES", "Aucun r√©sultat"): outils.append("Nmap")
    return outils

def detecter_vulnerabilites(texte):
    out = []
    for l in texte.splitlines():
        line = l.strip()
        if not line or "===" in line or "Aucun r√©sultat" in line or "Erreur" in line:
            continue
        if "Injection SQL" in line:
            out.append(("Injection SQL","Critique", line, "Utiliser des requ√™tes pr√©par√©es"))
        elif "XSS" in line and "aucun" not in line.lower():
            out.append(("XSS","Moyenne", line, "Filtrer et √©chapper les entr√©es utilisateur"))
        elif "[LOGIN PAGE]" in line:
            out.append(("Page de Login d√©tect√©e","Info", line, "Ajouter des protections"))
        elif "wildcard" in line:
            out.append(("Crossdomain non restreint","Moyenne", line, "Restreindre domaines XML"))
        elif "anti-clickjacking" in line:
            out.append(("Manque de X-Frame-Options","Faible", line, "Ajouter header X-Frame-Options"))
        elif "XSS protection" in line:
            out.append(("Manque de X-XSS-Protection","Faible", line, "Ajouter header X-XSS-Protection"))
        elif "MIME-sniffing" in line:
            out.append(("Manque de X-Content-Type-Options","Faible", line, "Ajouter header X-Content-Type-Options"))
    # d√©duplication
    seen=set(); res=[]
    for v in out:
        if v not in seen:
            seen.add(v); res.append(v)
    return res

def generer_resume_par_outil(texte, domaine):
    lignes = texte.splitlines()
    resume = {}
    current = None
    buffer = []
    nikto_idx = []
    subd, webt, who = [], [], []
    in_sub = in_web = in_who = False

    for idx, l in enumerate(lignes):
        line = l.strip()
        if line.startswith('====================') and line.endswith('===================='):
            # sauvegarde pr√©c√©dente
            if current:
                # Pour les sections SERVER et PORTS : on enl√®ve juste les lignes "Fichier:" et "V√©rifiez..."
                if ("INFORMATIONS SERVEUR" in current or "PORTS OUVERTS" in current):
                    filt = [
                        ln for ln in buffer
                        if not (ln.startswith("Fichier:") or ln.startswith("V√©rifiez les ports"))
                    ]
                    resume[current] = "\n".join(filt)
                # Nikto (comme avant)
                elif "nikto" in current.lower() and len(nikto_idx)>=2:
                    s,e = nikto_idx[0]+1, nikto_idx[-1]
                    resume["Nikto"] = "\n".join(lignes[s:e])
                # Reconnaissance
                elif "reconnaissance" in current.lower():
                    bloc=[]
                    if subd:
                        bloc.append("üõ∞Ô∏è Subfinder :")
                        bloc += [f"- {d}" for d in subd]
                    if webt:
                        bloc.append("\nüß† WebTech :")
                        bloc += [f"- {t}" for t in webt]
                    if who:
                        bloc.append("\nüìÑ WHOIS :")
                        bloc += [f"- {w}" for w in who]
                    else:
                        bloc.append("\nüìÑ WHOIS :")
                        bloc.append("- Aucune information fournie par WHOIS")
                    resume["Reconnaissance Domaine"] = "\n".join(bloc)
                # Autres sections
                elif buffer:
                    resume[current] = "\n".join(buffer)

            # r√©initialisation
            current = line
            buffer = []
            nikto_idx = []
            subd,webt,who = [],[],[]
            in_sub=in_web=in_who=False
            continue

        # traitement des lignes
        if current and "nikto" in current.lower():
            if "----" in line:
                nikto_idx.append(idx)
            buffer.append(line)

        elif current and "reconnaissance" in current.lower():
            if "Subfinder" in line:
                in_sub,in_web,in_who = True,False,False; continue
            if "WebTech" in line:
                in_sub,in_web,in_who = False,True,False; continue
            if "WHOIS" in line:
                in_sub,in_web,in_who = False,False,True; continue

            if in_sub and re.match(r'^[\w\.-]+\.[\w\.-]+$', line) and line.endswith("."+domaine):
                subd.append(line)
            elif in_web and line.startswith("-"):
                webt.append(line.lstrip("- ").strip())
            elif in_who:
                raw = line.lstrip("- ").strip()
                if ":" in raw and not raw.lower().startswith((">>>","to:")):
                    k,v = [p.strip() for p in raw.split(":",1)]
                    if not k.lower().startswith(("notice","terms","by")) and "REDACTED" not in v:
                        who.append(f"{k}: {v}")

        elif current:
            buffer.append(line)

    # derni√®re section
    if current:
        if ("INFORMATIONS SERVEUR" in current or "PORTS OUVERTS" in current):
            filt = [
                ln for ln in buffer
                if not (ln.startswith("Fichier:") or ln.startswith("V√©rifiez les ports"))
            ]
            resume[current] = "\n".join(filt)
        elif "nikto" in current.lower() and len(nikto_idx)>=2:
            s,e = nikto_idx[0]+1,nikto_idx[-1]
            resume["Nikto"] = "\n".join(lignes[s:e])
        elif "reconnaissance" in current.lower():
            bloc=[]
            if subd:
                bloc.append("üõ∞Ô∏è Subfinder :")
                bloc += [f"- {d}" for d in subd]
            if webt:
                bloc.append("\nüß† WebTech :")
                bloc += [f"- {t}" for t in webt]
            if who:
                bloc.append("\nüìÑ WHOIS :")
                bloc += [f"- {w}" for w in who]
            else:
                bloc.append("\nüìÑ WHOIS :")
                bloc.append("- Aucune information fournie par WHOIS")
            resume["Reconnaissance Domaine"] = "\n".join(bloc)
        elif buffer:
            resume[current] = "\n".join(buffer)

    return resume

def renumeroter_sections(soup):
    for i, div in enumerate(soup.find_all("div", class_="section"), start=1):
        h2 = div.find("h2")
        if h2 and re.match(r"\d+\.", h2.text.strip()):
            h2.string = re.sub(r"^\d+\.", f"{i}.", h2.text)

def ajouter_donnees_au_html(html_src, txt_path, html_out):
    texte  = lire_rapport_txt(txt_path)
    domaine= extraire_domaine_depuis_rapport(texte)
    soup   = BeautifulSoup(open(html_src, encoding='utf-8'), 'html.parser')

    outils  = detecter_outils_executes(texte)
    vulns   = detecter_vulnerabilites(texte)
    resumes = generer_resume_par_outil(texte, domaine)
    today   = datetime.datetime.now().strftime("%d/%m/%Y")

    # Section 1 ‚Äî Introduction
    sec1 = soup.find('h2', string=re.compile(r"1\. Introduction"))
    if sec1:
        p = sec1.find_next('p')
        if p:
            p.string = f"Ce rapport pr√©sente les r√©sultats du test d'intrusion effectu√© sur l'infrastructure du site {domaine} le {today}."

    # Section 3 ‚Äî R√©sum√© Ex√©cutif
    sec3 = soup.find('h2', string=re.compile(r"3\. R√©sum√© Ex√©cutif"))
    if sec3:
        p = sec3.find_next('p')
        if outils:
            p.string = f"Le test a permis d'identifier plusieurs vuln√©rabilit√©s √† l'aide des outils suivants : {', '.join(outils)}."
        else:
            p.string = "Aucun outil d√©tect√© comme ex√©cut√© dans le rapport."

    # Section 4 ‚Äî Vuln√©rabilit√©s
    sec4 = soup.find('h2', string=re.compile(r"4\. Vuln√©rabilit√©s Identifi√©es"))
    if sec4:
        tbl = sec4.find_next('table')
        if tbl:
            for tr in tbl.find_all('tr')[1:]:
                tr.decompose()
            for nom, grav, desc, reco in vulns:
                tr = soup.new_tag('tr')
                for v in (nom, grav, desc, reco):
                    td = soup.new_tag('td'); td.string = v; tr.append(td)
                tbl.append(tr)

    # Section 5 ‚Äî R√©sultats d√©taill√©s par outil
    sec5 = soup.new_tag('div', **{'class':'section'})
    h5   = soup.new_tag('h2'); h5.string="5. R√©sultats d√©taill√©s par outil"; sec5.append(h5)
    for o,cont in resumes.items():
        h3  = soup.new_tag('h3'); h3.string=f"üîé {o}"; sec5.append(h3)
        pre = soup.new_tag('pre'); pre.string = cont; sec5.append(pre)
    anchor = soup.find('h2', string=re.compile(r"5\. Recommandations G√©n√©rales"))
    if anchor:
        anchor.find_parent('div').insert_before(sec5)
    else:
        soup.body.append(sec5)

    # Section finale ‚Äî D√©tails Techniques
    final = soup.new_tag('div', **{'class':'section'})
    hfin   = soup.new_tag('h2'); hfin.string="D√©tails Techniques"; final.append(hfin)
    pfin   = soup.new_tag('p')
    pfin.append(BeautifulSoup(texte.replace('\n','<br>'), 'html.parser'))
    final.append(pfin)
    soup.body.append(final)

    renumeroter_sections(soup)
    with open(html_out, 'w', encoding='utf-8') as f:
        f.write(soup.prettify())
    print(f"‚úÖ Rapport g√©n√©r√© : {html_out}")

if __name__ == "__main__":
    src = "rapport.html"
    out = "rapport_complet.html"
    files = glob.glob("reports/security_report_*.txt")
    if files:
        files.sort(key=os.path.getmtime, reverse=True)
        ajouter_donnees_au_html(src, files[0], out)
    else:
        print("‚ùå Aucun rapport trouv√© dans 'reports/'")
